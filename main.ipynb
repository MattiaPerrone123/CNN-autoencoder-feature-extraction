{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.ndimage import label, rotate\n",
    "from skimage import measure\n",
    "\n",
    "#Medical Imaging\n",
    "import SimpleITK as sitk\n",
    "from monai.networks.nets import SwinUNETR\n",
    "import nibabel as nib\n",
    "\n",
    "#DL libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.image_preprocessing import(\n",
    "    preprocess_and_rotate_images_and_masks,\n",
    "    keep_largest_blob, \n",
    "    process_test_set_masks, \n",
    "    crop_and_pad_mask, \n",
    "    process_and_stack_masks, \n",
    "    separate_blobs,\n",
    "    MaskAlignerAllAngles)    \n",
    "    \n",
    "from src.utils import(\n",
    "    extract_number, \n",
    "    get_file_paths, \n",
    "    load_and_sort_files, load_tables,\n",
    "    process_files, \n",
    "    inference, \n",
    "    process_mismatched_data,\n",
    "    generate_outputs, \n",
    "    extract_latent_representations,\n",
    "    create_features_dataframe, \n",
    "    plot_correlation_matrix,\n",
    "    process_metadata_and_filter)\n",
    "    \n",
    "from src.data_loader import(\n",
    "    setup_training_pipeline, \n",
    "    extract_test_set, \n",
    "    create_dataloader_from_masks)    \n",
    "\n",
    "from src.model_training import(\n",
    "    train_and_validate,\n",
    "    initialize_training, \n",
    "    train_one_epoch, \n",
    "    train_model, load_model, \n",
    "    cross_validation_model_evaluation)\n",
    "\n",
    "from src.compute_geometry import(\n",
    "    compute_angles_for_masks, \n",
    "    rotate_masks_sequentially, \n",
    "    compute_disc_dimensions)\n",
    "\n",
    "from src.image_generation import process_latent_features_and_generate_images\n",
    "from src.config import config\n",
    "from src.autoencoder import Autoencoder\n",
    "from src.metrics import calculate_iou_list, get_iou_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Prepare Data\n",
    "images_dir, masks_dir, rad_grad_path, overview_path=get_file_paths(config[\"curr_path\"])\n",
    "sorted_files_img, sorted_files_msk, sorted_files_img_we, sorted_files_msk_we=load_and_sort_files(images_dir, masks_dir, extract_number)\n",
    "overview_table, rad_grad_table=load_tables(overview_path, rad_grad_path)\n",
    "\n",
    "#Process Files\n",
    "img_t1, img_t2, msk_t1_disk, msk_t2_disk, filename_t1, filename_t2, num_disc_table_t1, num_disc_table_t2, num_labels_real_t1_list, num_labels_real_t2_list=\\\n",
    "     process_files(sorted_files_img, sorted_files_img_we, images_dir, masks_dir, overview_table, config[\"target_resolution\"])\n",
    "\n",
    "\n",
    "#Preprocess Images and Masks\n",
    "img_t1_MRI, msk_t1_MRI=preprocess_and_rotate_images_and_masks(img_t1, msk_t1_disk)\n",
    "img_t2_MRI, msk_t2_MRI=preprocess_and_rotate_images_and_masks(img_t2, msk_t2_disk)\n",
    "\n",
    "\n",
    "#Setup Training Pipeline\n",
    "training_loader, testing_loader, model, optimizer, loss_fn=setup_training_pipeline(\n",
    "    img_t1_MRI, msk_t1_MRI,\n",
    "    img_size=config[\"img_size\"],\n",
    "    in_channels=config[\"in_channels\"],\n",
    "    out_channels=config[\"out_channels\"],\n",
    "    feature_size=config[\"feature_size\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    lr=config[\"lr\"],\n",
    "    test_size=config[\"test_size\"],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "#Train or Load Model\n",
    "training_results=train_and_validate(\n",
    "    model=model,\n",
    "    training_loader=training_loader,\n",
    "    testing_loader=testing_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=loss_fn,\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    device=config[\"device\"],\n",
    "    save_path=config[\"path_weights\"],\n",
    "    load_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "#Inference\n",
    "train_output, iou_list_train, dice_list_train=inference(\n",
    "    training_loader, training_results[\"model\"], config[\"batch_size\"], img_t1_MRI, (1 -config[\"test_size\"])\n",
    ")\n",
    "test_output, iou_list_test, dice_list_test=inference(\n",
    "    testing_loader, training_results[\"model\"], config[\"batch_size\"], img_t1_MRI, config[\"test_size\"]\n",
    ")\n",
    "\n",
    "#Process Mismatched Data\n",
    "img_t1_MRI_new, msk_t1_MRI_new, filename_t1_new, num_disc_table_t1_new, num_labels_real_t1_list_new, rad_grad_table_fin=process_mismatched_data(\n",
    "    img_t1_MRI=img_t1_MRI,\n",
    "    msk_t1_MRI=msk_t1_MRI,\n",
    "    filename_t1=filename_t1,\n",
    "    num_labels_real_t1_list=num_labels_real_t1_list,\n",
    "    num_disc_table_t1=num_disc_table_t1,\n",
    "    rad_grad_table=rad_grad_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Feature extraction and disc narrowing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing for autoencoder training\n",
    "msk_t1_MRI_new_test=extract_test_set(msk_t1_MRI_new, img_t1_MRI, config[\"test_size\"])\n",
    "msk_t1_MRI_single=process_test_set_masks(msk_t1_MRI_new_test)\n",
    "msk_t1_MRI_single_def=process_and_stack_masks(msk_t1_MRI_single)\n",
    "training_img_msk_real=create_dataloader_from_masks(msk_t1_MRI_single_def, config[\"batch_size_ae\"])\n",
    "\n",
    "\n",
    "#Initialize and train or load the autoencoder \n",
    "autoencoder=Autoencoder()\n",
    "if config[\"load_weights_ae\"]:\n",
    "    ae_model=load_model(autoencoder, config[\"weights_path_ae\"])\n",
    "    print(\"Model loaded. Training skipped.\")\n",
    "else:\n",
    "    ae_model=train_model(autoencoder, training_img_msk_real, num_epochs=config[\"num_epochs_ae\"], lr=config[\"learning_rate_ae\"], save_path=config[\"weights_path_ae\"])\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "#Extract latent representations using the trained/pretrained autoencoder\n",
    "output_num=generate_outputs(ae_model, training_img_msk_real, config[\"device\"])\n",
    "latent_representations=extract_latent_representations(ae_model, training_img_msk_real, config[\"device\"])\n",
    "iou_list=calculate_iou_list(torch.tensor(msk_t1_MRI_single_def), output_num, get_iou_train)\n",
    "\n",
    "# Compute geometric and latent features for the masks\n",
    "sag_angle, trasv_angle, front_angle=compute_angles_for_masks(msk_t1_MRI_single_def)\n",
    "rotated_masks_t1_MRI=rotate_masks_sequentially(msk_t1_MRI_single_def)\n",
    "disc_height_list, ap_width_list, lat_width_list=compute_disc_dimensions(rotated_masks_t1_MRI)\n",
    "\n",
    "geom_features_df, latent_features_df, all_features_df=create_features_dataframe(\n",
    "    disc_height_list, \n",
    "    ap_width_list, \n",
    "    lat_width_list, \n",
    "    sag_angle, \n",
    "    trasv_angle, \n",
    "    front_angle, \n",
    "    latent_representations\n",
    ")\n",
    "\n",
    "\n",
    "#Filter metadata and making disc narrowing predictions\n",
    "filtered_metadata=process_metadata_and_filter('annotations.xlsx', filename_t1_new, test_size=42)\n",
    "feature_columns=[filtered_metadata.columns[10]]\n",
    "\n",
    "f1_scores_tot, accuracy_scores_tot=cross_validation_model_evaluation(\n",
    "    geom_features_df,\n",
    "    filtered_metadata,\n",
    "    feature_columns,\n",
    "    config[\"f1_score_type\"],\n",
    "    random_state=config[\"random_state\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the correlation matrix between latent and geometric features\n",
    "plot_correlation_matrix(all_features_df)\n",
    "\n",
    "#Generate synthetic images by varying latent features \n",
    "images_arr, latent_features_list_fin=process_latent_features_and_generate_images(\n",
    "    latent_representations=latent_representations, \n",
    "    decoder=ae_model.decoder,\n",
    "    numb_plots=6, \n",
    "    latent_dim=4,\n",
    "    view=\"sagittal\"  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "R3U_VIsbg8ce",
    "1NzTMSYkg8ce",
    "BIK5fjnbg8cf",
    "VWNIFOG-g8cf",
    "GITgM3L8g8cg"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
